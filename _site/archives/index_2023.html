<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>SMRT Reading Group</title>

<!-- Put meta information here. -->
<link rel="stylesheet" href="main.css">
</head>
<body style="max-width: 800px; margin-left: auto; margin-right: auto">
<table width="100%" border="0" cellspacing="0" cellpadding="0">

<!-- Body of page. -->
<tr>
  <td><table border="0" cellspacing="0" cellpadding="0">
    <tr>
      <td class="lciBody">

<h1>SMRT Reading Group</h1>
<h2>
	<p style="color:rgb(153,153,153)"> The website of the reading group SMRT (Sensorimotor Reading
    and Thinking) at UBC. To remember the acronym, think of Homer Simpson singing, 
    <a href="http://www.youtube.com/watch?v=DhrfhjLd9e4">"I am so smart, I am so smart, S-M-R-T."</a>
    </p>
</h2>
<br/>

<table width="100%" border="0" cellspacing="0" cellpadding="0">
  <tr>
  <td><img height=120 src="pics/flubber.png"></td>
  <td><img height=120 src="pics/coala.png"></td>
  <td><img height=120 src="pics/man_boob.png"></td>
  <td><img height=120 src="pics/ball_cloth.png"></td>
  <td><img height=120 src="pics/plant.png"></td>
  </tr>
</table>
<br><br>

<!-- What do we read? -->
<h2 id="theme">What Do We Read?</h2>
<p>
  <b>Theme.</b> The theme of this reading group is <em>artificial intelligence and computer graphics</em>.
  On the graphics side our focus spans multiple topics:
  <ul>
      <li>Simulation and control of (non-) human characters; </li>
      <li>Geometric and/or biomechanical modelling of human body, skin, muscles and other tissues;</li>
      <li>Biomechanical simulation of musculoskeletal structures;</li>
      <li>Novel learning-based methods for differentiable simulation;</li>
      <li>Vision-based methods of human motion capture, analysis and synthesis.</li>
  </ul>
</p>
<p>
  <b>Publication venues.</b> We get to pick papers from a multitude of publication venues since
  our theme is quite interdisciplinary:
  <ul>
      <li>Graphics: ACM SIGGRAPH, ToG, SCA, Eurographics;</li>
      <li>Vision: ICCV, CVPR;</li>
      <li>Robotics: ICRA, IROS;</li>
      <li>Machine Learning: NeurIPS, ICML, ICLR.</li>
  </ul>
The above list is not exhaustive and we welcome our fellow readers to suggest relevant papers from
other venues. Ideally we will focus on more recent (ex. SIGGRAPH 2019) papers but there will be room for
relevant, older papers. Textbook chapters are also welcome, so long as they are relevant and accessible
to everyone.
</p>
<p>
  <b>Upcoming, finished and suggested papers. </b>
  A schedule of upcoming papers can be found below under the heading <a href="#upcoming"><i>Upcoming
  Papers</i></a>. Under the heading <a href="#finished"><i>Finished Papers</i></a> is a log of earlier
  topics. A list of papers to potentially discuss in the future are listed under
  <a href="#suggested"><i>Suggested Papers</i></a>.
</p>

<!-- Location and Time -->
<br>
<h2 id="loc_and_time">Location, Time, and How to Join Us</h2>
<p>
  <b> Location and time.</b> Our meetings take place every two weeks on Friday at 12:00PM, virtually
  on Zoom. We will send you a Google Calendar invite with Zoom link included once you have joined the group.  
</p>
<p>
  <b>Intended audience.</b> We welcome any UBC student with some background and interest in computer graphics,
  machine learning, physics-based simulation, vision-based motion understanding to join our group. Very few
  students in the group are experts in all or any of the above topics, so please don't feel intimidated!
</p>
<p>
  <b>Want to join us?</b> Please post an issue on
  <a href="https://github.com/ericchen321/ai4d/issues">this page</a> and include your UBC email in it.
  And we will be in touch with you.
</p>
<br>

<!-- How do we read papers? -->
<br>
<h2 id="structure">How Do We Read Papers?</h2>
<p>
  Each week someone presents a paper/tutorial, followed by discussion.
  For paper discussions, we structure each session around answering the following questions:
</p>
<p>
<ul>
    <li>Motivation and Contribution
      <ul>
          <li>What problem is the authors addressing? Are the authors qualified to provide an answer?</li>
          <li>Is the problem too broad? Too narrow?</li>
          <li>How does it relate to our topic(s) of interest?</li>
          <li>What are the implications of these results to theory, practice
            and/or future research in the field? </li>
      </ul>
    </li>
    <li>Method
      <ul>
        <li>What solution is offered to the problem? How does it work?</li>
        <li>Does the solution solve the stated problem?</li>
        <li>How does the author justify the solution: data, logic, experience,
          examples? Is the justification technically correct? Is it sufficient?</li>
      </ul>
    </li>
    <li>Limitations
      <ul>
        <li>How does it compare to existing methods? </li>
        <li>What assumptions and/or restrictions are made? Are they appropriate?</li>
      </ul>
    </li>
    <li>Related Work
      <ul>
        <li>What alterative solutions and related work are presented?</li>
        <li>What distinguishes other work from this one?</li>
        <li>Are too many of the citations to the author’s own work?</li>
        <li>Are there any citations missing?</li>
      </ul>
    </li>
</ul>
</p>
<p>
  The above questions are taken from
  <a href="https://www.cs.ubc.ca/~mitchell/Class/CS513.2009W1/Handouts/howToReview.pdf">
    "Reading and Reviewing Academic Articles"
  </a>
  by Prof. Ian M Mitchell also at UBC.
</p>
<br>

<br>
<!-- Schedule for upcoming papers. -->
<h2 id="upcoming">Upcoming Papers</h2>
<dl>
  <dl>
    <dt><em>Feb 17, 2023 - Lead: Niloofar Khoshsiyar</em>
      <dt><strong>COUCH: Towards Controllable Human-Chair Interactions</strong></dt>
      <dd> Xiaohan Zhang, Bharat Lal Bhatnagar, Vladimir Guzov, Sebastian Starke, Gerard Pons-Moll
        <br> ECCV 2022
        <br> [<a href="https://arxiv.org/abs/2205.00541">Paper</a>]
      </dd>
    
    <dt><em>Feb 3, 2023 - Lead: Guanxiong Chen</em>
      <dt><strong>Interactive Modelling of Volumetric Musculoskeletal Anatomy</strong></dt>
      <dd> Rinat Abdrashitov, Seungbae Bang, David I.W. Levin, Karan Singh, Alec Jacobson
        <br> SIGGRAPH 2021
        <br> [<a href="https://arxiv.org/abs/2106.05161">Paper</a>]
      </dd>
  </dl>
</dl>
<br>

<!-- Log of finished papers. -->
<h2 id="finished">Finished Papers (April 2022 - )</h2>
<p>
  Note: this list contains only a subset of papers we have discussed. The complete list is on a Slack
  channel, but we are not able to retrieve it since Slack hides it from us (which is because we are on
  a free plan :( )
</p>
<dl>
  <dl>
    <dt><em>Dec 16, 2022; Jan 6, 2023 - Lead: Guanxiong Chen</em>
      <dt><strong>Reconstructing Personalized Anatomical Models for Physics-based Body Animation</strong></dt>
      <dd> Petr Kadlecek (*), Alexandru-Eugen Ichim (*), Tiantian Liu, Jaroslav Krivanek, Ladislav Kavan.
        <br> ToG 2016
        <br> [<a href="https://www.cs.utah.edu/~ladislav/kadlecek16reconstructing/kadlecek16reconstructing.html">Paper</a>]
      </dd>

    <dt><em>Dec 2, 2022 - Lead: Yuhao Wu</em>
      <dt><strong>Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations</strong></dt>
      <dd> Francesco Locatello, Stefan Bauer, Mario Lucic, Gunnar Rätsch, Sylvain Gelly, Bernhard Schölkopf, Olivier Bachem
        <br> ICML 2019
        <br> [<a href="https://arxiv.org/abs/1811.12359">Paper</a>]
      </dd>

    <dt><em>Nov 4, 2022 - Lead: Guanxiong Chen</em>
      <dt><strong>Differentiable Simulation of Inertial Musculotendons</strong></dt>
      <dd> Ying Wang, Jasper Verheul, Sang-Hoon Yeo, Nima Khademi Kalantari, Shinjiro Sueda
        <br> SIGGRAPH Asia 2022
        <br> [<a href="https://arxiv.org/abs/2202.02344">Paper</a>]
      </dd>

    <dt><em>Aug 26, 2022; Sept 23, 2022 - Lead: Guanxiong Chen</em>
      <dt><strong>NeuralSim: Augmenting differentiable simulators with neural networks</strong></dt>
      <dd> Eric Heiden, David Millard, Erwin Coumans, Yizhou Sheng, Gaurav S. Sukhatme
        <br> ICRA 2021
        <br> [<a href="https://arxiv.org/abs/2011.04217">Paper</a>]
      </dd>

    <dt><em>July 15, 2022 - Lead: Guanxiong Chen</em>
      <dt><strong>Differentiable Dynamics for Articulated 3d Human Motion Reconstruction</strong></dt>
      <dd> Erik Gärtner, Mykhaylo Andriluka, Erwin Coumans, Cristian Sminchisescu
        <br> CVPR 2022
        <br> [<a href="https://arxiv.org/abs/2205.12256">Paper</a>]
      </dd>

    <dt><em>April 1, 2022 - Lead: Guanxiong Chen</em>
      <dt><strong>Inferring Articulated Rigid Body Dynamics from RGBD Video</strong></dt>
      <dd> Eric Heiden, Ziang Liu, Vibhav Vineet, Erwin Coumans, Gaurav S. Sukhatme
        <br> IROS 2022
        <br> [<a href="https://eric-heiden.github.io/video2sim/">Paper</a>]
      </dd>
  </dl>
</dl>
<br>

<h2 id="suggested">Suggested Papers</h2>
<dl>
  <dt><em>Suggested by: Niloofar Khoshsiyar</em>
    <dt><strong>We are More than Our Joints: Predicting how 3D Bodies Move</strong></dt>
    <dd> Zhang, Yan and Black, Michael J and Tang, Siyu
      <br> CVPR 2021
      <br> Highlights: From Michael J Black's group
      <br> [<a href="https://yz-cnsdqz.github.io/eigenmotion/MOJO/index.html/">Project</a>]
    </dd>

  <dt><em>Suggested by: Niloofar Khoshsiyar</em>
    <dt><strong>Synthesizing Long-Term 3D Human Motion and Interaction in 3D Scenes</strong></dt>
    <dd> Jiashun Wang, Huazhe Xu, Jingwei Xu, Sifei Liu, Xiaolong Wang
      <br> CVPR 2021
      <br> [<a href="https://jiashunwang.github.io/Long-term-Motion-in-3D-Scenes/">Project</a>]
    </dd>

  <dt><em>Suggested by: Guanxiong Chen</em>
    <dt><strong>Deep learning of biomimetic sensorimotor control for biomechanical human animation</strong></dt>
    <dd> Masaki Nakada, Tao Zhou, Honglin Chen, Tomer Weiss, and Demetri Terzopoulos.
      <br> ToG 2018
      <br> Highlights: 1) cited many of Dinesh's papers. So I guess quite relevant?
      <br> [<a href="https://dl.acm.org/doi/10.1145/3197517.3201305">Paper</a>]
    </dd>

  <dt><em>Suggested by: Guanxiong Chen</em>
    <dt><strong>Fast and Feature-Complete Differentiable Physics for Articulated Rigid Bodies with Contact</strong></dt>
    <dd> Keenon Werling, Dalton Omens, Jeongseok Lee, Ioannis Exarchos, C. Karen Liu
      <br> Robotics: Science and Systems 2021
      <br> Highlights: 1) Proposed the Nimble physics engine which's fully differentiable; 
        2) Comes with a muscle-actuated differentiable humanoid model.
      <br> [<a href="https://arxiv.org/abs/2103.16021">Paper</a>]
    </dd>
  
  <dt><em>Suggested by: Guanxiong Chen</em>
    <dt><strong>RedMax: Efficient & Flexible Approach for Articulated Dynamics</strong></dt>
    <dd> Ying Wang, Nicholas J. Weidner, Margaret A. Baxter, Yura Hwang, Danny M. Kaufman, and Shinjiro Sueda.
      <br> SIGGRAPH 2019 (Vol. 38, No. 4, Article 104),
      <br> [<a href="http://faculty.cs.tamu.edu/sueda/projects/redmax/">Paper</a>]
    </dd>
</dl>
<br>

<h2>Archives of this Page</h2>
<p>
  Below you can find the rich history of this reading group, including papers proposed and
  presented by our holy ancestors.
</p>
<dl>
  <dt><a href="archives/index_2020_b.html">2020 Version of this page</a>
  <dt><a href="archives/index2015.html">2015 Version of this page</a>
</dl>

<!--
<ul>
  <li>
      <b>The tendon network of the fingers performs anatomical computation at a macroscopic scale. </b>
      Valero-Cuevas, F.J.;   Jae-Woong Yi;   Brown, D.;   McNamara, R.V.;   Paul, C.;   Lipson, H.;   
      [<a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4203030">External link</a>]
  </li>
</ul>
-->

</table></td></tr>
</table></body>
</html>
